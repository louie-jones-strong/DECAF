{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Formatting\n",
    "\n",
    "This notebook was used for collecting and formatting the results of the experiments, for the evaluation section of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import src.Common.Utils.Config.ConfigHelper as ConfigHelper\n",
    "import shutil\n",
    "import src.Common.EpisodeReplay.EpisodeReplay as EpisodeReplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunGroup = \"12\"\n",
    "EnvNames = [\"FrozenLake\"]\n",
    "BehaviouralTypes = [\"Human\", \"Curated\", \"HighScore\"]\n",
    "\n",
    "\n",
    "# manual Review of the results config\n",
    "MaxChoicesPerAgent = 5\n",
    "MaxReplaysPerChoice = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied Human Demos for: FrozenLake\n",
      "Added 59 Human episodes to FrozenLake\n",
      "Added 23 Curated episodes to FrozenLake\n",
      "Added 82 HighScore episodes to FrozenLake\n"
     ]
    }
   ],
   "source": [
    "# copy demos of each behavioural type to the run group folder\n",
    "def CopyDemos(envName, runGroup):\n",
    "\tfromPath = os.path.join(\"Data\", envName, \"dev\", \"replays\", \"Human\")\n",
    "\ttoPath = os.path.join(\"Data\", envName, runGroup, \"replays\", \"Human\")\n",
    "\n",
    "\tif os.path.exists(toPath):\n",
    "\t\tshutil.rmtree(toPath)\n",
    "\tshutil.copytree(fromPath, toPath)\n",
    "\n",
    "\tprint(\"Copied Human Demos for: \" + envName)\n",
    "\treturn\n",
    "\n",
    "def AddDemoIdsToBehaviour(envName, runGroup, behaviourType):\n",
    "\t# load the results\n",
    "\tstatsPath = os.path.join(\"Data\", envName, runGroup, \"replays\", \"Human\", \"stats.tsv\")\n",
    "\tstats = pd.read_csv(statsPath, sep=\"\\t\")\n",
    "\n",
    "\tlowerBehaviourType = behaviourType.lower()\n",
    "\n",
    "\tstats[\"Behaviour\"] = stats[\"loggerName\"].apply(lambda x: x.split(\"_\")[-2])\n",
    "\n",
    "\tif lowerBehaviourType != \"highscore\":\n",
    "\t\tstats = stats[stats[\"Behaviour\"] == lowerBehaviourType]\n",
    "\n",
    "\tepisodeIds = stats[\"EpisodeId\"].unique().tolist()\n",
    "\n",
    "\tloggerName = \"Human_\" + behaviourType\n",
    "\n",
    "\t# load the json with the episode Ids of the behavioural type\n",
    "\tepisodeIdsPath = os.path.join(\"Data\", envName, runGroup, f\"{behaviourType}_Episodes.json\")\n",
    "\t\n",
    "\tepisodeIdsJson = ConfigHelper.LoadConfig(episodeIdsPath)\n",
    "\tepisodeIdsJson[loggerName] = episodeIds\n",
    "\n",
    "\tConfigHelper.SaveConfig(episodeIdsJson, episodeIdsPath)\n",
    "\n",
    "\tprint(f\"Added {len(episodeIds)} {behaviourType} episodes to {envName}\")\n",
    "\treturn\n",
    "\n",
    "for envName in EnvNames:\n",
    "\tCopyDemos(envName, RunGroup)\n",
    "\n",
    "\tfor behaviourType in BehaviouralTypes:\n",
    "\t\tAddDemoIdsToBehaviour(envName, RunGroup, behaviourType)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Replays For Manual Reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 92 replays to review for Human in FrozenLake\n",
      "Collected 85 replays to review for Curated in FrozenLake\n"
     ]
    }
   ],
   "source": [
    "def LoadReplay(envName, runGroup, agentType, episodeId):\n",
    "\t\n",
    "\tpath = os.path.join(\"Data\", envName, runGroup, \"replays\", agentType, episodeId)\n",
    "\ttry:\n",
    "\t\treplay = EpisodeReplay.EpisodeReplay.LoadFromFolder(path)\n",
    "\t\treturn replay\n",
    "\texcept:\n",
    "\t\treturn None\n",
    "\n",
    "def CollectReplaysToReview(envName, runGroup, behaviourType):\n",
    "\tepisodeIdsPath = os.path.join(\"Data\", envName, runGroup, f\"{behaviourType}_Episodes.json\")\n",
    "\treplays =  ConfigHelper.LoadConfig(episodeIdsPath)\n",
    "\n",
    "\tcolumns = [\"AgentId\", \"Predicted\", \"AgentType\"]\n",
    "\tcolumns += [f\"Replay_{i}\" for i in range(MaxReplaysPerChoice)]\n",
    "\n",
    "\treplaysToReview = pd.DataFrame(columns=columns)\n",
    "\n",
    "\tfor agentId, episodeIds in replays.items():\n",
    "\t\t\n",
    "\t\tagentType = agentId.split(\"_\")[0]\n",
    "\t\tids = []\n",
    "\n",
    "\t\tfor i in range(len(episodeIds)):\n",
    "\t\t\tepisodeId = episodeIds[i]\n",
    "\n",
    "\t\t\treplay = LoadReplay(envName, runGroup, agentType, episodeId)\n",
    "\t\t\tif replay is None:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tids.append(episodeId)\n",
    "\n",
    "\t\t\tif len(ids) >= MaxReplaysPerChoice or i == len(episodeIds) - 1:\n",
    "\t\t\t\trow = {}\n",
    "\t\t\t\trow[\"AgentId\"] = [agentId]\n",
    "\t\t\t\trow[\"Predicted\"] = [None]\n",
    "\t\t\t\trow[\"AgentType\"] = [agentType]\n",
    "\t\t\t\tfor i, id in enumerate(ids):\n",
    "\t\t\t\t\trow[f\"Replay_{i}\"] = [id]\n",
    "\n",
    "\t\t\t\treplaysToReview = pd.concat([replaysToReview, pd.DataFrame(row)], ignore_index=True)\n",
    "\t\t\t\tids = []\n",
    "\n",
    "\treturn replaysToReview\n",
    "\t\n",
    "for envName in EnvNames:\n",
    "\tfor behaviourType in BehaviouralTypes:\n",
    "\n",
    "\t\tif behaviourType == \"HighScore\":\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\treplaysToReview = CollectReplaysToReview(envName, RunGroup, behaviourType)\n",
    "\t\treplaysToReview = replaysToReview.sample(frac=1)\n",
    "\t\treplaysToReviewPath = os.path.join(\"Data\", envName, RunGroup, f\"ReplaysToReview_{behaviourType}.json\")\n",
    "\t\treplaysToReview.to_json(replaysToReviewPath, orient=\"records\", indent=4)\n",
    "\n",
    "\t\tprint(f\"Collected {len(replaysToReview)} replays to review for {behaviourType} in {envName}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formate the results of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Predicted</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Norm_Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgentType</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HardCoded</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>100%</td>\n",
       "      <td>133%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>75%</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>100%</td>\n",
       "      <td>133%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted     Percent Norm_Percent\n",
       "              count sum                     \n",
       "AgentType                                   \n",
       "HardCoded        20  20    100%         133%\n",
       "Human            20  15     75%         100%\n",
       "ML               40  40    100%         133%\n",
       "Random           20   0      0%           0%"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviourReviewResults = pd.read_json(replaysToReviewPath)\n",
    "grouped = behaviourReviewResults.groupby(\"AgentType\").aggregate({\"Predicted\": [\"count\", \"sum\"]})\n",
    "\n",
    "\n",
    "grouped[\"Percent\"] = grouped[\"Predicted\"][\"sum\"] / grouped[\"Predicted\"][\"count\"]\n",
    "grouped[\"Norm_Percent\"] = grouped[\"Percent\"] / grouped[\"Percent\"][\"Human\"]\n",
    "\n",
    "# format the percent columns\n",
    "grouped[\"Percent\"] = grouped[\"Percent\"].apply(lambda x: f\"{x:.0%}\")\n",
    "grouped[\"Norm_Percent\"] = grouped[\"Norm_Percent\"].apply(lambda x: f\"{x:.0%}\")\n",
    "\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables of agents' results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = [\"FrozenLake\", \"CartPole\"]\n",
    "agents = [\"Human\", \"Random\", \"HardCoded\", \"ML\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadStats(envName, runGroup, agent):\n",
    "\tpath = os.path.join(\"Data\", envName, runGroup, \"replays\", agent, \"stats.tsv\")\n",
    "\tdf = pd.read_csv(path, sep=\"\\t\")\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data\\\\FrozenLake\\\\6\\\\replays\\\\ML\\\\stats.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m LoadStats(\u001b[39m\"\u001b[39;49m\u001b[39mFrozenLake\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m6\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mML\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m df\n",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m, in \u001b[0;36mLoadStats\u001b[1;34m(envName, runGroup, agent)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mLoadStats\u001b[39m(envName, runGroup, agent):\n\u001b[0;32m      2\u001b[0m \tpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39mData\u001b[39m\u001b[39m\"\u001b[39m, envName, runGroup, \u001b[39m\"\u001b[39m\u001b[39mreplays\u001b[39m\u001b[39m\"\u001b[39m, agent, \u001b[39m\"\u001b[39m\u001b[39mstats.tsv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \tdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(path, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \t\u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\louie\\Documents\\Git\\Uni-Dissertation\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\louie\\Documents\\Git\\Uni-Dissertation\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\louie\\Documents\\Git\\Uni-Dissertation\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\louie\\Documents\\Git\\Uni-Dissertation\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\louie\\Documents\\Git\\Uni-Dissertation\\.venv\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data\\\\FrozenLake\\\\6\\\\replays\\\\ML\\\\stats.tsv'"
     ]
    }
   ],
   "source": [
    "df = LoadStats(\"FrozenLake\", \"6\", \"ML\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Mean</th>\n",
       "      <th>Random sem</th>\n",
       "      <th>Random n</th>\n",
       "      <th>HardCoded Mean</th>\n",
       "      <th>HardCoded sem</th>\n",
       "      <th>HardCoded n</th>\n",
       "      <th>ML(Real Sim) Mean</th>\n",
       "      <th>ML(Real Sim) sem</th>\n",
       "      <th>ML(Real Sim) n</th>\n",
       "      <th>ML(Learned Model) Mean</th>\n",
       "      <th>ML(Learned Model) sem</th>\n",
       "      <th>ML(Learned Model) n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FrozenLake</th>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>991.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>0.719595</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>592.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CartPole</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Random Mean  Random sem  Random n  HardCoded Mean  HardCoded sem  \\\n",
       "FrozenLake     0.004036    0.002015     991.0             1.0            0.0   \n",
       "CartPole            NaN         NaN       NaN             NaN            NaN   \n",
       "\n",
       "            HardCoded n  ML(Real Sim) Mean  ML(Real Sim) sem  ML(Real Sim) n  \\\n",
       "FrozenLake        990.0           0.719595          0.018478           592.0   \n",
       "CartPole            NaN                NaN               NaN             0.0   \n",
       "\n",
       "            ML(Learned Model) Mean  ML(Learned Model) sem  ML(Learned Model) n  \n",
       "FrozenLake                     1.0                    0.0               2097.0  \n",
       "CartPole                     163.0                    NaN                  1.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def EnvFitAgentSummary(summaries, df, agentName):\n",
    "\tmean = df[\"EpisodeTotalReward\"].mean()\n",
    "\tsem = df[\"EpisodeTotalReward\"].sem()\n",
    "\n",
    "\tsummaries[f\"{agentName} Mean\"] = mean\n",
    "\tsummaries[f\"{agentName} sem\"] = sem\n",
    "\tsummaries[f\"{agentName} n\"] = len(df)\n",
    "\n",
    "\treturn summaries\n",
    "\n",
    "def GetEnvFitSummary(envName, runGroup):\n",
    "\t\n",
    "\tsummaries = {}\n",
    "\n",
    "\tfor agent in agents:\n",
    "\t\ttry:\n",
    "\t\t\tdf = LoadStats(envName, runGroup, agent)\n",
    "\n",
    "\t\t\tif agent == \"ML\":\n",
    "\t\t\t\trealSim = df.loc[df[\"UseRealSim\"] == True]\n",
    "\t\t\t\tsummaries = EnvFitAgentSummary(summaries, realSim, f\"{agent}(Real Sim)\")\n",
    "\n",
    "\t\t\t\tlearnedSim = df.loc[df[\"UseRealSim\"] == False]\n",
    "\t\t\t\tsummaries = EnvFitAgentSummary(summaries, learnedSim, f\"{agent}(Learned Model)\")\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tsummaries = EnvFitAgentSummary(summaries, df, agent)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\n",
    "\t# summaryDf = pd.DataFrame(summaries)\n",
    "\treturn summaries\n",
    "\n",
    "def GetEnvsSummary(runGroup):\n",
    "\tsummaries = {}\n",
    "\n",
    "\tfor env in envs:\n",
    "\t\tsummaries[env] = GetEnvFitSummary(env, runGroup)\n",
    "\n",
    "\tdf = pd.DataFrame(summaries)\n",
    "\tdf = df.transpose()\n",
    "\treturn df\n",
    "\n",
    "df = GetEnvsSummary(\"6\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Mean</th>\n",
       "      <th>Random sem</th>\n",
       "      <th>Random n</th>\n",
       "      <th>HardCoded Mean</th>\n",
       "      <th>HardCoded sem</th>\n",
       "      <th>HardCoded n</th>\n",
       "      <th>ML(Real Sim) Mean</th>\n",
       "      <th>ML(Real Sim) sem</th>\n",
       "      <th>ML(Real Sim) n</th>\n",
       "      <th>ML(Learned Model) Mean</th>\n",
       "      <th>ML(Learned Model) sem</th>\n",
       "      <th>ML(Learned Model) n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FrozenLake</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>991.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.018</td>\n",
       "      <td>592.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CartPole</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Random Mean Random sem Random n HardCoded Mean HardCoded sem  \\\n",
       "FrozenLake       0.004      0.002    991.0            1.0           0.0   \n",
       "CartPole           nan        nan      nan            nan           nan   \n",
       "\n",
       "           HardCoded n ML(Real Sim) Mean ML(Real Sim) sem ML(Real Sim) n  \\\n",
       "FrozenLake       990.0              0.72            0.018          592.0   \n",
       "CartPole           nan               nan              nan            0.0   \n",
       "\n",
       "           ML(Learned Model) Mean ML(Learned Model) sem ML(Learned Model) n  \n",
       "FrozenLake                    1.0                   0.0              2097.0  \n",
       "CartPole                    163.0                   nan                 1.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
