{
	"UseRealSim": true,
	"HardcodedConfig": {
		"PlayStyleWeights": {
			"Normal": 0.5,
			"Human": 0.0,
			"PlayStyle": 0.0
		}
	},
	"MonteCarloConfig": {
		"MaxSecondsPerAction": 10,
		"CacheTreeBetweenActions": true,
		"CacheTreeBetweenEpisodes": true,
		"ActionSelectionTemperature": 0.01,
		"SelectionConfig": {
			"MaxSelectionsPerAction": 256,
			"TrainExploreFactor": 0.5,
			"TestExploreFactor": 0.5,
			"MaxTreeDepth": 10
		},
		"RollOutConfig": {
			"MaxRollOutCount": 32,
			"MaxRollOutDepth": 6,
			"ValueFinalStates": true,
			"TimeOutAllowed": false
		},
		"NodeScoreConfig": {
			"RolloutRewardsMultiplier": 1.0,
			"PredictedValueMultiplier": 0.0,
			"PlayStyleWeights": {
				"Human": 1.0,
				"Curated": 1.0
			}
		}
	},
	"LearnerConfig": {
		"MaxInFlightSamples": 3,
		"DataCollectionMultiplier": 1
	},
	"ModelConfigs": {
		"Value": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "Value_Trajectories",
			"ReplayExamples": "",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.0,
			"L2": 0.0
		},
		"Forward_NextState": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "Forward_NextState_Trajectories",
			"ReplayExamples": "",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.5,
			"L2": 0.5
		},
		"Forward_Reward": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "Forward_Reward_Trajectories",
			"ReplayExamples": "",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.5,
			"L2": 0.5
		},
		"Forward_Terminated": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "Forward_Terminated_Trajectories",
			"ReplayExamples": "",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.5,
			"L2": 0.5
		},
		"Human_Discriminator": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "PlayStyle_Trajectories",
			"ReplayExamples": "human",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.0,
			"L2": 0.0
		},
		"PlayStyle_Discriminator": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "PlayStyle_Trajectories",
			"ReplayExamples": "curated",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.0,
			"L2": 0.0
		}
	},
	"DataTables": [
		{
			"TableName": "Forward_NextState_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0.8,
			"Columns": [
				"CurrentState",
				"NextState",
				"Action"
			]
		},
		{
			"TableName": "Forward_Reward_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0.8,
			"Columns": [
				"CurrentState",
				"Action",
				"Reward"
			]
		},
		{
			"TableName": "Forward_Terminated_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0.8,
			"Columns": [
				"CurrentState",
				"Action",
				"Terminated"
			]
		},
		{
			"TableName": "Value_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0.8,
			"Columns": [
				"CurrentState",
				"NextState",
				"Action",
				"Reward",
				"MaxFutureRewards",
				"Terminated",
				"Truncated"
			]
		},
		{
			"TableName": "PlayStyle_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0,
			"Columns": [
				"CurrentState",
				"NextState",
				"Action",
				"Reward",
				"MaxFutureRewards",
				"Terminated",
				"Truncated"
			]
		}
	]
}