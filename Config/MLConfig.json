{
	"MaxInFlightSamples": 3,
	"DataCollectionMultiplier": 1,
	"MaxSecondsPerAction": 10,
	"MaxSelections": 256,
	"CacheTree": true,
	"ExploreFactor": 0.5,
	"RollOutConfig": {
		"MaxRollOutCount": 1024,
		"MaxRollOutDepth": 32,
		"ValueFinalStates": true,
		"TimeOutAllowed": false
	},
	"ModelConfigs": {
		"Value": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "Value_Trajectories",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.0,
			"L2": 0.0
		},
		"Forward": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "Forward_Trajectories",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.5,
			"L2": 0.5
		},
		"Forward_NextState": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "Forward_NextState_Trajectories",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.5,
			"L2": 0.5
		},
		"Forward_Reward": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "Forward_Reward_Trajectories",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.5,
			"L2": 0.5
		},
		"Forward_Terminated": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "Forward_Terminated_Trajectories",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.5,
			"L2": 0.5
		},
		"PlayStyleDiscriminator": {
			"TrainingBatchSize": 2048,
			"MaxDeploymentBatchSize": 2048,
			"DataTable": "Human_Trajectories",
			"LearningRate": 0.001,
			"DenseLayers": [256, 256],
			"Activations": "relu",
			"Dropout": 0.5,
			"L1": 0.0,
			"L2": 0.0

		}
	},
	"DataTables": [
		{
			"TableName": "Forward_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0.8,
			"Columns": [
				"CurrentState",
				"NextState",
				"Action",
				"Reward",
				"MaxFutureRewards",
				"Terminated",
				"Truncated"
			]
		},
		{
			"TableName": "Forward_NextState_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0.8,
			"Columns": [
				"CurrentState",
				"NextState",
				"Action",
				"Reward",
				"MaxFutureRewards",
				"Terminated",
				"Truncated"
			]
		},
		{
			"TableName": "Forward_Reward_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0.8,
			"Columns": [
				"CurrentState",
				"NextState",
				"Action",
				"Reward",
				"MaxFutureRewards",
				"Terminated",
				"Truncated"
			]
		},
		{
			"TableName": "Forward_Terminated_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0.8,
			"Columns": [
				"CurrentState",
				"NextState",
				"Action",
				"Reward",
				"MaxFutureRewards",
				"Terminated",
				"Truncated"
			]
		},
		{
			"TableName": "Value_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0.8,
			"Columns": [
				"CurrentState",
				"NextState",
				"Action",
				"Reward",
				"MaxFutureRewards",
				"Terminated",
				"Truncated"
			]
		},
		{
			"TableName": "Human_Trajectories",
			"StepCount": 1,
			"MinCount": 1000,
			"MaxCount": 1000000,
			"PriorityExponent": 0,
			"Columns": [
				"CurrentState",
				"NextState",
				"Action",
				"Reward",
				"MaxFutureRewards",
				"Terminated",
				"Truncated"
			]
		}
	]
}